{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Assignment)\n",
    "\n",
    "This notebook is for you to practice skills during lecture.\n",
    "\n",
    "Today's guided module project and assignment will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills.\n",
    "\n",
    "## Sections\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy\n",
    "* <a href=\"#p4\">Part 4</a>: Post Lecture Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  from collections import Mapping, defaultdict\n",
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_lg' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package punkt to /Users/codyreece/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/codyreece/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/lightgbm/__init__.py:42: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  warnings.warn(\"Starting from version 2.2.1, the library file in distribution wheels for macOS \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#other imports for testing\n",
    "import unidecode\n",
    "from word2number import w2n\n",
    "import gensim.downloader as api\n",
    "\n",
    "#ntlk imports\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "\n",
    "#tokenizing\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#lemmitizing\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#modeling\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4087, 3) (1022, 2)\n"
     ]
    }
   ],
   "source": [
    "# Bringing in the data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1747    \\nLight straw. Initially this is quite hot and a little dumb, with whiffs of Indian spice — think turmeric and curry leaf — along with mint sauce (but no lamb) and a tickle of peat. The palate is quite intense and hot, with powdered almond, a grassy edge, and concentrated sweetness that starts in the center and builds toward the back palate. Subtle, but can’t help wishing there was just a little more say from the cask. £59                                                                                      \n",
       "2905    \\nWillingly, we travel further along the Big Dipper with whisky maker Henric Molin. His latest creation exudes rich, dark, chewy toffee, Brazil nut shells, chopped dates, licorice, stone fruits, grilled beef mushrooms, and worked leather. The flavor starts slowly, like trying to ignite a fire of damp twigs. Once established, there is good weight and density, with treacle, dried fig, black cherry, and cinnamon, but the finish diminishes quickly after swallowing, leaving blackened oak and burnt sugar. 795 SEK\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 0)\n",
    "train['description'].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.704918\n",
       "0    0.279178\n",
       "2    0.015904\n",
       "Name: ratingCategory, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of ratingCategory: 0 (Excellent), 1 (Good), 2 (Poor)\n",
    "train.ratingCategory.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-cf08eddbe278>:2: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>\\nAn uncommon exclusive bottling of a 6 year old cask strength malt. Light gold in color, the nose is vegetal, more peat bog than peat smoke, with an undercurrent of pastry cream and rose. It’s an odd combination of aromas. The entry is flavorful and inviting with smoked pineapple, clove, and rose. Peak smoke arrives in full force in the mid-palate, which drops the sweet and becomes spicy. The finish is mostly smoke, but with a pleasant minty coolness.  (Wyoming only)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  \\\n",
       "1  3861   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                description  \\\n",
       "1  \\nAn uncommon exclusive bottling of a 6 year old cask strength malt. Light gold in color, the nose is vegetal, more peat bog than peat smoke, with an undercurrent of pastry cream and rose. It’s an odd combination of aromas. The entry is flavorful and inviting with smoked pineapple, clove, and rose. Peak smoke arrives in full force in the mid-palate, which drops the sweet and becomes spicy. The finish is mostly smoke, but with a pleasant minty coolness.  (Wyoming only)   \n",
       "\n",
       "   ratingCategory  \n",
       "1  0               "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Excellent\" category\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "train[train.ratingCategory == 0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>5078</td>\n",
       "      <td>\\nIts best attributes are vanilla, toasted coconut, and tropical fruit, but the rest of this grain whisky is a bit of a disappointment. It is thin, and at times harsh. A paint thinner component is evident (especially on the nose), along with more wood on the finish than this thin body can handle. Two Carsebridge grain Scotch whiskies from Duncan Taylor which I have tasted recently were much better: richer and creamier, and with more balance.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  \\\n",
       "3504  5078   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                        description  \\\n",
       "3504  \\nIts best attributes are vanilla, toasted coconut, and tropical fruit, but the rest of this grain whisky is a bit of a disappointment. It is thin, and at times harsh. A paint thinner component is evident (especially on the nose), along with more wood on the finish than this thin body can handle. Two Carsebridge grain Scotch whiskies from Duncan Taylor which I have tasted recently were much better: richer and creamier, and with more balance.   \n",
       "\n",
       "      ratingCategory  \n",
       "3504  2               "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read a few reviews from the \"Poor\" category\n",
    "train[train.ratingCategory == 2].sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Training Set into Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2043,) (2044,) (2043,) (2044,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train['description'], \n",
    "                                                    train['ratingCategory'], \n",
    "                                                    test_size=0.5, \n",
    "                                                    stratify=train['ratingCategory'],\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2255    \\nThe tenth limited release of Grandeur was matured in a mix of Pedro Ximénez and oloroso sherry casks. It offers a nose of ginger, raisins, old leather, smoky orange, blackcurrants, and walnuts. The palate is voluptuous, with full sherry notes, figs, dates, cinnamon, and cloves. Licorice and spicy dark chocolate in the lingering finish. (240 bottles for the U.S.)\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(X):\n",
    "    \n",
    "    X = X.apply(lambda x: x.lower())\n",
    "    X = X.apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    X = X.apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2255    the tenth limited release of grandeur was matured in a mix of pedro ximnez and oloroso sherry casks it offers a nose of ginger raisins old leather smoky orange blackcurrants and walnuts the palate is voluptuous with full sherry notes figs dates cinnamon and cloves licorice and spicy dark chocolate in the lingering finish  bottles for the us\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = clean_text(X_train)\n",
    "X_val = clean_text(X_val)\n",
    "X_val.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/codyreece/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#stopwords\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2255    tenth limited release grandeur matured mix pedro ximnez oloroso sherry casks offers nose ginger raisins old leather smoky orange blackcurrants walnuts palate voluptuous full sherry notes figs dates cinnamon cloves licorice spicy dark chocolate lingering finish bottles us\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to remove stopwords\n",
    "def no_stop(X):\n",
    "\n",
    "    X = X.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    return X\n",
    "\n",
    "X_train = no_stop(X_train)\n",
    "X_val = no_stop(X_val)\n",
    "X_val.head(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2255    [tenth, limited, release, grandeur, matured, mix, pedro, ximnez, oloroso, sherry, casks, offers, nose, ginger, raisins, old, leather, smoky, orange, blackcurrants, walnuts, palate, voluptuous, full, sherry, notes, figs, dates, cinnamon, cloves, licorice, spicy, dark, chocolate, lingering, finish, bottles, us]\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizing\n",
    "# import nltk \n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def tokeitup(X):\n",
    "    X = X.apply(lambda x: word_tokenize(x))\n",
    "\n",
    "    return X\n",
    "\n",
    "#applying tokenizing function\n",
    "X_train = tokeitup(X_train)\n",
    "X_val = tokeitup(X_val)\n",
    "X_val.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import PorterStemmer \n",
    "# def word_stemmer(text):\n",
    "#     stem_text = [PorterStemmer().stem(i) for i in text]\n",
    "#     return stem_text\n",
    "# X_train = X_train.apply(lambda x: word_stemmer(x))\n",
    "#X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2255    [tenth, limited, release, grandeur, matured, mix, pedro, ximnez, oloroso, sherry, cask, offer, nose, ginger, raisin, old, leather, smoky, orange, blackcurrants, walnut, palate, voluptuous, full, sherry, note, fig, date, cinnamon, clove, licorice, spicy, dark, chocolate, lingering, finish, bottle, u]\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatizing\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [WordNetLemmatizer().lemmatize(i) for i in text]\n",
    "    return lem_text\n",
    "X_train = X_train.apply(lambda x: word_lemmatizer(x))\n",
    "X_val = X_val.apply(lambda x: word_lemmatizer(x))\n",
    "X_val.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tagging\n",
    "# def word_pos_tagger(text):\n",
    "#     pos_tagged_text = nltk.pos_tag(text)\n",
    "#     return pos_tagged_text\n",
    "\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# X_train = X_train.apply(lambda x: word_pos_tagger(x))\n",
    "# X_val = X_val.apply(lambda x: word_pos_tagger(x))\n",
    "# X_val.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #chunking\n",
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "# doc = nlp(str(X_train[:1]))\n",
    "\n",
    "# for chunk in doc.noun_chunks:\n",
    "#     print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "#             chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes to X_train:\n",
      "3923    [highrye, bourbon, mashbill, small, batch, whiskey, annual, limited, release, nose, offer, inviting, medley, chocolatecovered, cherry, pound, cake, buttered, toast, blackberry, licorice, palate, mellow, honeyed, note, cedar, chocolate, chip, cooky, blackberry, jam, coconut, shaving, cigar, wrapper, completed, finish, brown, sugar, chocolate, peanut, shell, cracked, pepper]\n",
      "Name: description, dtype: object\n",
      "____\n",
      "Data type for X_train: \n",
      "<class 'pandas.core.series.Series'>\n",
      "____\n",
      "(2043,)\n",
      "_________________\n",
      "_________________\n",
      "Changes to X_val:\n",
      "_____\n",
      "2255    [tenth, limited, release, grandeur, matured, mix, pedro, ximnez, oloroso, sherry, cask, offer, nose, ginger, raisin, old, leather, smoky, orange, blackcurrants, walnut, palate, voluptuous, full, sherry, note, fig, date, cinnamon, clove, licorice, spicy, dark, chocolate, lingering, finish, bottle, u]\n",
      "Name: description, dtype: object\n",
      "_____\n",
      "Data type for X_val: \n",
      "<class 'pandas.core.series.Series'>\n",
      "_____\n",
      "(2044,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Changes to X_train:\")\n",
    "print(X_train.head(1))\n",
    "print(\"____\")\n",
    "\n",
    "print(\"Data type for X_train: \")\n",
    "print(type(X_train))\n",
    "print(\"____\")\n",
    "print(X_train.shape)\n",
    "print(\"_________________\")\n",
    "print(\"_________________\")\n",
    "print(\"Changes to X_val:\")\n",
    "print(\"_____\")\n",
    "print(X_val.head(1))\n",
    "print(\"_____\")\n",
    "print(\"Data type for X_val: \")\n",
    "print(type(X_val))\n",
    "print(\"_____\")\n",
    "print(X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_join = X_train.apply(lambda x: \" \".join(x))\n",
    "X_val_join = X_val.apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4087,) (2043,) (2044,) (2043,) (2044,)\n"
     ]
    }
   ],
   "source": [
    "print(train['description'].shape, X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2255    [tenth, limited, release, grandeur, matured, mix, pedro, ximnez, oloroso, sherry, cask, offer, nose, ginger, raisin, old, leather, smoky, orange, blackcurrants, walnut, palate, voluptuous, full, sherry, note, fig, date, cinnamon, clove, licorice, spicy, dark, chocolate, lingering, finish, bottle, u]                                                                            \n",
       "3847    [little, beauty, maple, syrup, pecan, sliced, peach, vanillaladen, breadandbutter, pudding, soft, bakedapple, tart, smooth, sticky, toffee, pudding, red, apple, oozing, caramel, fine, layer, spice, mouthfeel, silky, rounded, effortlessly, elegant, finish, walnut, clove, marron, glac, douglas, laing, brought, amazing, grain, lately, better, ever, kl, wine, exclusive, bottle]\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for the best number of workers\n",
    "N_JOBS = [None, 1, 2, 3, 4, -1]\n",
    "import time\n",
    "for n_jobs in N_JOBS:\n",
    "        start = time.perf_counter()\n",
    "        print('n_jobs = {}, perf_counter = {}'.format(n_jobs, time.perf_counter() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "rfc = RandomForestClassifier()\n",
    "lbm = LGBMClassifier(random_state=42, objective='binary', reg_lambda=0.2)\n",
    "xgb = XGBClassifier(objective = 'multi:softmax', num_class = 6,\n",
    "                                       booster='gbtree',eta =.1,  max_depth = 12,\n",
    "                                       subsample=.8, n_estimators=120, random_state = 42,\n",
    "                                       eval_metric = 'merror', colsample_bytree = 1,\n",
    "                                       tree_method = 'exact', maximize=False)\n",
    "vect2 = CountVectorizer()\n",
    "svd = TruncatedSVD()\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect2), \n",
    "#                  ('svd', svd),\n",
    "                 # Classifier\n",
    "                 ('clf', lbm)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "parameters = {\n",
    "#     'vect__max_df': np.linspace(0.1, 1, 10),\n",
    "#     'vect__min_df': (.01, .02),\n",
    "#     'vect__max_features': (2500, 5000, 10000, 12000),\n",
    "#     'vect__norm': [None, 'l1', 'l2'],\n",
    "#     'vect__binary': [True, False],\n",
    "#     'clf__alpha': np.linspace(0.5, 1.5, 6),\n",
    "#     'clf__fit_prior': [True, False]\n",
    "    \n",
    "    'clf__n_estimators':( 10, 25, 50, 100),\n",
    "    'clf__max_depth':(6, 7, 8, 9, 12, 15),\n",
    "    'clf__boosting_type':('gbdt', 'dart'),\n",
    "    'clf__num_leaves': (75, 100),\n",
    "    'clf__learning_rate': (.2, .3, .4), \n",
    "    'clf__feature_fraction': (.5, .75, .9)\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipe,parameters, cv=32, n_jobs=-1, verbose=10) #GridSearchCV RandomizedSearchCV\n",
    "grid_search.fit(X_train_join, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File\n",
    "*Note:* In a typical Kaggle competition, you are only allowed two submissions a day, so you only submit if you feel you cannot achieve higher test accuracy. For this competition the max daily submissions are capped at **20**. Submit for each demo and for your assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subNumber = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve a minimum of 70% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "vect2 = CountVectorizer()\n",
    "svd = TruncatedSVD(n_components=100,\n",
    "                   random_state=42,# Just here for demo. \n",
    "                   algorithm='randomized')\n",
    "lbm = LGBMClassifier(random_state=42, objective='binary', reg_lambda=0.2)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', vect2),      # TF-IDF Vectorizer\n",
    "    ('svd', svd),        # Truncated SVD Dimensionality Reduction\n",
    "    ('clf', mnb)         # RandomForest Classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Your Search Space\n",
    "You're looking for both the best hyperparameters of your vectorizer and your classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': np.linspace(0.1, 1, 10),\n",
    "    'vect__min_df': (.01, .02),\n",
    "    'vect__max_features': (2500, 5000, 10000, 12000, 15000, 99999),\n",
    "    'vect__norm': [None, 'l1', 'l2'],\n",
    "    'vect__binary': [True, False],\n",
    "    'clf__alpha': np.linspace(0.5, 1.5, 6),\n",
    "    'clf__fit_prior': [True, False]\n",
    "#     'vect__max_df': (.3, .4, .5),\n",
    "#     'vect__min_df': (.005, .01, .02),\n",
    "#     'vect__max_features': (1200, 2500, 5000, 10000, 12000),\n",
    "#     'clf__n_estimators':( 10, 25, 50, 100),\n",
    "#     'clf__max_depth':(6, 7, 8, 9, 12, 15),\n",
    "#     'clf__boosting_type':('gbdt', 'dart'),\n",
    "#     'clf__num_leaves': (50, 75, 100),\n",
    "#     'clf__learning_rate': (.2, .3, .4), \n",
    "#     'clf__feature_fraction': (.5, .75, .9)\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(pipe,parameters, cv=50, n_jobs=-1, verbose=10)\n",
    "grid_search.fit(X_train_join, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = grid_search.predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "\n",
    "submission.to_csv(f'./whiskey-reviews-dspt7/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to your Dataset\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth' : randint(3,10),\n",
    "    'min_samples_leaf': randint(2,15)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Word Embedding Work Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on test sample\n",
    "pred = ...predict(test['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id'], 'ratingCategory':pred})\n",
    "submission['ratingCategory'] = submission['ratingCategory'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Sure the Category is an Integer\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your Submission File\n",
    "# Best to Use an Integer or Timestamp for different versions of your model\n",
    "submission.to_csv(f'./whiskey-reviews-dspt7/submission{subNumber}.csv', index=False)\n",
    "subNumber += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Lecture Assignment\n",
    "<a id=\"p4\"></a>\n",
    "\n",
    "Your primary assignment this afternoon is to achieve a minimum of 70% accuracy on the Kaggle competition. Once you have achieved 70% accuracy, please work on the following: \n",
    "\n",
    "1. Research \"Sentiment Analysis\". Provide answers in markdown to the following questions: \n",
    "    - What is \"Sentiment Analysis\"? \n",
    "    - Is Document Classification different than \"Sentiment Analysis\"? Provide evidence for your response\n",
    "    - How do create labeled sentiment data? Are those labels really sentiment?\n",
    "    - What are common applications of sentiment analysis?\n",
    "2. Research our why word embeddings worked better for the lecture notebook than on the whiskey competition.\n",
    "    - This [text classification documentation](https://developers.google.com/machine-learning/guides/text-classification/step-2-5) from Google might be of interest\n",
    "    - Neural Networks are becoming more popular for document classification. Why is that the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
