{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSPT6_LS_DS_414_Topic_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "U4-S1-NLP",
      "language": "python",
      "name": "u4-s1-nlp"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cOMBkFKn6uEK"
      },
      "source": [
        "# Topic Modeling (Prepare)\n",
        "\n",
        "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
        "\n",
        "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
        "\n",
        "## Use Cases\n",
        "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
        "* Identifying common themes in customer reviews\n",
        "* Discovering the needle in a haystack \n",
        "* Monitoring communications (Email - State Department) \n",
        "\n",
        "## Learning Objectives\n",
        "*At the end of the lesson you should be able to:*\n",
        "* Part 0: Warm-Up\n",
        "* Part 1: Describe how an LDA Model works\n",
        "* Part 2: Estimate a LDA Model with Gensim\n",
        "* Part 3: Interpret LDA results & Select the appropriate number of topics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cxH0cRGX6uEL"
      },
      "source": [
        "# Part 0: Warm-Up\n",
        "How do we do a grid search? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFjplZ7r3Lyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rnyNg8sQ6uEL",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:17: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
            "  from collections import Mapping, defaultdict\n",
            "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
            "  from numpy.core.umath_tests import inner1d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "boKWVkRz6uEO",
        "colab": {}
      },
      "source": [
        "data = fetch_20newsgroups()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hPpukADi7Ofv",
        "colab": {}
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g9Jhb3j-7_e2",
        "colab": {}
      },
      "source": [
        "data['target_names']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JbVoIoMm8HbR",
        "colab": {}
      },
      "source": [
        "data['data'][1000]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\nSubject: Diamond SS24X, Win 3.1, Mouse cursor\\nOrganization: National Library of Medicine\\nLines: 10\\n\\n\\nAnybody seen mouse cursor distortion running the Diamond 1024x768x256 driver?\\nSorry, don't know the version of the driver (no indication in the menus) but it's a recently\\ndelivered Gateway system.  Am going to try the latest drivers from Diamond BBS but wondered\\nif anyone else had seen this.\\n\\npost or email\\n\\n--Don Lindbergh\\ndabl2@lhc.nlm.nih.gov\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "w-39zg9a6uEQ"
      },
      "source": [
        "### GridSearch on Just Classifier\n",
        "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2q3NmHEo6uEQ",
        "colab": {}
      },
      "source": [
        "v1 = TfidfVectorizer()\n",
        "X_train = v1.fit_transform(data['data'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LX3a4nUI6uES",
        "colab": {}
      },
      "source": [
        "p1 = {\n",
        "    'n_estimators':[10,20],\n",
        "    'max_depth': [None, 7]\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7OfA7KNQ6uEU",
        "colab": {}
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "gs1 = GridSearchCV(clf, p1, cv=5,n_jobs=-1, verbose=1)\n",
        "gs1.fit(X_train, data['target'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   23.6s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise',\n",
              "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False),\n",
              "       fit_params=None, iid=True, n_jobs=-1,\n",
              "       param_grid={'n_estimators': [10, 20], 'max_depth': [None, 7]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cMq_hw5W6uEX",
        "colab": {}
      },
      "source": [
        "#gs1.predict([\"Sample text\"])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDkMaXvG83Zt",
        "colab": {}
      },
      "source": [
        "test_sample = v1.transform([\"Sample text\"])\n",
        "test_sample.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BLgsZtKJ8o01",
        "colab": {}
      },
      "source": [
        "pred = gs1.predict(test_sample)\n",
        "pred"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLGkB8Vz9Otq",
        "colab": {}
      },
      "source": [
        "data['target_names'][pred[0]]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'misc.forsale'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WdVTuXKl6uEZ"
      },
      "source": [
        "### GridSearch with BOTH the Vectoizer & Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "97TjUtoI6uEZ",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Create a pipeline with a vectorize and a classifier\n",
        "# 2. Use Grid Search to optimize the entire pipeline"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IdIE67Us6uEc",
        "colab": {}
      },
      "source": [
        "# pred = gs2.predict([\"Sample text\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gs2' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-eecd45d73159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sample text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gs2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xhcb5G0W-Dch",
        "colab": {}
      },
      "source": [
        "# data['target_names'][pred[0]]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F2R2ACd36uEd"
      },
      "source": [
        "Advantages to using GS with the Pipe:\n",
        "* Allows us to make predictions on raw text increasing reproducibility. :)\n",
        "* Allows us to tune the parameters of the vectorizer along side the classifier. :D "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xbZjG6U86uEe"
      },
      "source": [
        "# Part 1: Describe how an LDA Model works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMzU-XOM3LzW",
        "colab_type": "text"
      },
      "source": [
        "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n",
        "\n",
        "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/)\n",
        "\n",
        "[Topic Modeling with Gensim](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yPIlE_IeF0cX",
        "colab": {}
      },
      "source": [
        "# Download spacy model\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ Skipping model package dependencies and setting `--no-deps`. You\n",
            "don't seem to have the spaCy package itself installed (maybe because you've\n",
            "built from source?), so installing the model dependencies would cause spaCy to\n",
            "be downloaded, which probably isn't what you want. If the model package has\n",
            "other dependencies, you'll have to install them manually.\u001b[0m\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qapChu_UGBFc",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "import spacy\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/codyreece/.vscode/extensions/ms-python.python-2020.10.332292344/pythonFiles/lib/python/past/types/oldstr.py:23: DeprecationWarning: invalid escape sequence \\d\n  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qaMsy1XAGLxc",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({\n",
        "    'content': data['data'],\n",
        "    'target': data['target'],\n",
        "    'target_names': [data['target_names'][i] for i in data['target']]\n",
        "})\n",
        "df"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 content  target  \\\n",
              "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
              "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
              "2      From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4   \n",
              "3      From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1   \n",
              "4      From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14   \n",
              "...                                                  ...     ...   \n",
              "11309  From: jim.zisfein@factory.com (Jim Zisfein) \\n...      13   \n",
              "11310  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...       4   \n",
              "11311  From: westes@netcom.com (Will Estes)\\nSubject:...       3   \n",
              "11312  From: steve@hcrlgw (Steven Collins)\\nSubject: ...       1   \n",
              "11313  From: gunning@cco.caltech.edu (Kevin J. Gunnin...       8   \n",
              "\n",
              "                   target_names  \n",
              "0                     rec.autos  \n",
              "1         comp.sys.mac.hardware  \n",
              "2         comp.sys.mac.hardware  \n",
              "3                 comp.graphics  \n",
              "4                     sci.space  \n",
              "...                         ...  \n",
              "11309                   sci.med  \n",
              "11310     comp.sys.mac.hardware  \n",
              "11311  comp.sys.ibm.pc.hardware  \n",
              "11312             comp.graphics  \n",
              "11313           rec.motorcycles  \n",
              "\n",
              "[11314 rows x 3 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>target</th>\n      <th>target_names</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n      <td>7</td>\n      <td>rec.autos</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n      <td>1</td>\n      <td>comp.graphics</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n      <td>14</td>\n      <td>sci.space</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11309</th>\n      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n      <td>13</td>\n      <td>sci.med</td>\n    </tr>\n    <tr>\n      <th>11310</th>\n      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n      <td>4</td>\n      <td>comp.sys.mac.hardware</td>\n    </tr>\n    <tr>\n      <th>11311</th>\n      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n      <td>3</td>\n      <td>comp.sys.ibm.pc.hardware</td>\n    </tr>\n    <tr>\n      <th>11312</th>\n      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n      <td>1</td>\n      <td>comp.graphics</td>\n    </tr>\n    <tr>\n      <th>11313</th>\n      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n      <td>8</td>\n      <td>rec.motorcycles</td>\n    </tr>\n  </tbody>\n</table>\n<p>11314 rows × 3 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "na2bkOcFGter",
        "colab": {}
      },
      "source": [
        "# For reference on regex: https://docs.python.org/3/library/re.html\n",
        "\n",
        "# From 'content' column: \n",
        "# 1. Remove whitespace \n",
        "\n",
        "# 2. Remove Emails\n",
        "\n",
        "# 3. Remove new line characters\n",
        "\n",
        "# 4. Remove non-alphanumeric characters\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2prKILFo3Lzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkgfv9tc3Lzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize(progress_bar=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/opt/anaconda3/envs/U4-S1-NLP/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandarallel'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-9a07cb44748d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandarallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandarallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpandarallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandarallel'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSW10Cb33Lzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6EBPQXqEKE9P",
        "colab": {}
      },
      "source": [
        "# Create 'lemmas' column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-yvsyIpvKBlw",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPuCuK0z3Lzs",
        "colab_type": "text"
      },
      "source": [
        "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1klqRpqtJxWc",
        "colab": {}
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(df['lemmas'] )\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in df['lemmas']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ArZPxcP5LH1J",
        "colab": {}
      },
      "source": [
        "id2word[200]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IIBnI2e3Lzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['content'][5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGFG9E2j3Lzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB6wox963Lz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word[252]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk3g75XX3Lz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word[276]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6K2jWxHJLOzK",
        "colab": {}
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[(id2word[word_id], word_count) for word_id, word_count in corpus[5]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le-XzI923Lz8",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Estimate a LDA Model with Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlNG4bSI3Lz8",
        "colab_type": "text"
      },
      "source": [
        " ### Train an LDA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fasvjf0VLQ2a",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "#                                            id2word=id2word,\n",
        "#                                            num_topics=20, \n",
        "#                                            chunksize=100,\n",
        "#                                            passes=10,\n",
        "#                                            per_word_topics=True)\n",
        "\n",
        "# # https://radimrehurek.com/gensim/models/ldamodel.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49CabmIj3Lz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lda_model.save('lda_model.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDgUshRE3L0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "#                                                         id2word=id2word,\n",
        "#                                                         num_topics=20, \n",
        "#                                                         chunksize=100,\n",
        "#                                                         passes=10,\n",
        "#                                                         per_word_topics=True,\n",
        "#                                                         workers=12)\n",
        "\n",
        "# # https://radimrehurek.com/gensim/models/ldamulticore.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgb9AaPq3L0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lda_multicore.save('lda_multicore.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLxvJPoK3L0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim import models\n",
        "lda_multicore =  models.LdaModel.load('lda_multicore.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDH3tzx13L0I",
        "colab_type": "text"
      },
      "source": [
        "### View the topics in LDA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JawR8yscLVNS",
        "colab": {}
      },
      "source": [
        "pprint(lda_multicore.print_topics())\n",
        "doc_lda = lda_multicore[corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKEP0bIC3L0K",
        "colab_type": "text"
      },
      "source": [
        "### What is topic Perplexity?\n",
        "Perplexity is a statistical measure of how well a probability model predicts a sample. As applied to LDA, for a given value of , you estimate the LDA model. Then given the theoretical word distributions represented by the topics, compare that to the actual topic mixtures, or distribution of words in your documents.\n",
        "\n",
        "### What is topic coherence?\n",
        "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
        "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xCjhr8k4LXSy",
        "colab": {}
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_multicore.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_multicore, \n",
        "                                     texts=df['lemmas'], \n",
        "                                     dictionary=id2word, \n",
        "                                     coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UvfgYt93L0X",
        "colab_type": "text"
      },
      "source": [
        "# Part 3: Interpret LDA results & Select the appropriate number of topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CYXi480VLaHK",
        "colab": {}
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_multicore, corpus, id2word)\n",
        "pyLDAvis.display(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rjtXk8J3LaXC",
        "colab": {}
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
        "                                                        id2word=id2word,\n",
        "                                                        num_topics=num_topics, \n",
        "                                                        chunksize=100,\n",
        "                                                        passes=10,\n",
        "                                                        per_word_topics=True,\n",
        "                                                        workers=12)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRA9EjvQ3L0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "# model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=df['lemmas'], start=2, limit=40, step=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e9X-Ql-3L0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "coherence_values = [0.5054, 0.5332, 0.5452, 0.564, 0.5678, 0.5518, 0.519]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybEBYQNF3L0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmvQ2zKZ3L0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yol5vG3R3L0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select the model and print the topics\n",
        "#optimal_model = model_list[4]\n",
        "optimal_model =  models.LdaModel.load('optimal_model.model')\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "pprint(optimal_model.print_topics(num_words=10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HwVEUDI3L0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}